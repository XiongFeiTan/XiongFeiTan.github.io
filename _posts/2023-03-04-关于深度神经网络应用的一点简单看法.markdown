---
layout: post
title: 关于深度神经网络的实际应用方法论
categories: [深度学习]
comments: true
description: 在深度神经网络应用当中什么样的方法流程值得借鉴？为啥神经网络难以训练？
---


## 整体流程？
💡  我们知道深度神经网络的实际应用效果，已经得到了充分的验证，实践中经常发现，对实际业务场景来说，正确使用一个普通算法通常比盲目草率地使用一个不清楚的算法效果来的更好。

那实际应用当中什么样的方法流程值得**借鉴**呢？

1. 明确目标需要**解决什么样的问题**。
2. 利用简单算法建立简单的**基准**。
3. 搭建一个端到端的工作流程，包括**目标损失函数的定义**、性能度量等。
4. 搭建系统，确定性能瓶颈，是否过拟合，欠拟合等
5. 根据具体任务进行**增量式的改动**，包括是否需要收集新数据、增加或者减少模型容量，添加或者删除正则化项、调整超参数、改进数据集的准确性等
6. 实际业务**场景数据中**进行评估验证。


## 算法难训练？
💡  对于深度神经网络，我们首先会直觉地认为增加多个隐藏层应当能让网络能够学习到更加复杂的函数，然后可以再推理的时候表现的更好。但实际工作当中发现好像并不是这样，并不是网络结构越复杂效果越好，那应该是怎么样呢？
假设额外的隐藏层的确能够在原理上起到作用，那问题应该就是是我们的学习算法没有发现正确的权值和偏置。那么就要看看学习算法本身哪里出现了问题，并搞清楚如何进行改进。

深入发现，算法难训练在于深度神经网络中基于梯度学习的**不稳定性**（梯度消失、梯度爆炸）、**激活函数的选择、权重的初始化**，甚至是学习算法的实现方式也扮演了重要的⻆色，**网络结构和其他超参数本身**也是很重要的。因此，太多因子影响了训练神经网络的难度，理解所有这些因子仍然是当前研究实践的重点。




































