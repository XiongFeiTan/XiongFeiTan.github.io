---
layout: post
title: decision-tree
categories: [spark mllib]
comments: true
description: 总结决策树相关要点
---

决策树

------

 决策树可以看成一个if-then规则集合，具有“互斥完备”性质 。决策树基本上都是采用的是贪心的算法，自顶向下递归分治构造。

ID3,C4.5,CART等：

各种决策树算法之间的主要区别在于：分成的组之间差异的衡量方式不一样。

ID3基于信息增益，C4.5基于信息增益率，CART基于基尼不纯度来划分。

------

随机森林是决策树的组合算法，组合多个决策树的目的是为了降低过拟合的风险。

运用随机森林预测结果降低了预测的方差，提高了在测试数据上的表现。



------

GBDT（梯度提升决策树）

而Gradient Boost与传统的Boost的区别是，每一次的计算是为了减少上一次的残差(residual)，而为了消除残差，我们可以在残差减少的梯度方向上建立一个新的模型。

GB算法框架中放入决策树，就是GBDT，分为两个版本：

**残差版本** 

**梯度版本** 

两者的不同主要在于每步迭代时，是否使用梯度作为求解方法。前者不用梯度而是用残差—-**残差是全局最优值**，梯度是局部最优方向步长，即前者每一步都在试图让结果变成最好，后者则每步试图让结果更好一点。

------

