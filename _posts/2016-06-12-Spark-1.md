---
layout: post
title: Spark Quick Start
comments: true
categories: [Spark]
tags: [tool]
---

<h3>Spark Quick Start Documentation</h3>

---
概述
在快速学习语言或者框架，Hadoop,Spark等生态系统之前，首先需要进行环境配置搭建和各种版本的选择。因为我们知道目前大数据学习的各种框架，各种版本之间还是有一定的差异的。在这里选择的，都是相对比较稳定的版本，当然也可以考虑官方资料选择其他合适的版本来进行学习。

---
<h3>环境：</h3>
Ubuntu14.04 64 位   

Java:jdk-8u91-linux-i586.tar.gz  

Hadoop :hadoop-2.6.4.tar.gz  

Spark:spark-1.6.1-bin-hadoop2.6.tgz  

Scala:Scala-2.11.6.tgz  

---

<h2>环境搭建</h2>

<h3>* 1,安装 SSH 配置 SSH 无密码登录<h3>

---

<h4>第一个问题 ，SSH 是什么？</h4>
通俗的说，SSH 是一种网络协议，用于网络上计算机之间的加密登录。用户可以从本地计算机，使用 SSH 协议登录另外一台远程计算机，   

而且这种登录是比较安全的。 如你可以登录某台 Linux 主机， 并且在上面运行命令。

---

<h4>第二个问题 ，SSH 基本使用？</h4>

学习 Spark,Hadoop 等大数据框架，单节点模式，伪集群，集群都需要用到 SSH 登录，如果使用密码登录，每次都必须输入密码，非常麻烦。  

SSH 提供了公钥登录，可以省去输入密码的步骤。公钥登录原理很简单，就是用户将自己的公钥储存在远程主机上。  

登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。    

远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录 shell，不再要求密码。  

这种方法要求用户必须提供自己的公钥。如果没有现成的，可以直接用 ssh-keygen 命令生成一个。  

本文档选择的操作系统 Ubuntu 默认已安装了 SSH client，还需要安装SSH server。  

sustc@ubuntu:~$ sudo apt‐get install openssh‐server #  

---

<h3>* 2,安装 SSH 服务<h3>  

sustc@ubuntu:~$ ssh localhost # 登录本地系统

<h5>首先</h5>  

退出刚才的 SSH，就回到了我们原先的终端窗口，

<h5>然后</h5>
利用 ssh-keygen 生成密钥， 在$HOME/.ssh/目录下， 会新生成两个文件：  

id_rsa.pub 和 id_rsa。前者是你的公钥，后者是你的私钥。并将密钥加入到授权中。

---

操作命令如下：

---

* sustc@ubuntu:~$ exit # 退出刚才的 ssh localhost
* sustc@ubuntu:~$ cd ~/.ssh/ # 进入本地的 ssh 文件夹中
* sustc@ubuntu:~$ ssh‐keygen ‐t rsa # 密码输入，回车
* sustc@ubuntu:~$ cat ./id_rsa.pub >> ./authorized_keys #  

* 将本地的公钥文件~/.ssh/id_rsa.pub， 重定向追加到远程 （本地）文件 authorized_keys 的末尾。

---

* sustc@ubuntu:~$ ssh‐add
* sustc@ubuntu:~$ ssh localhost # 测试能否登录本地系统  


![](http://ockqhxx9g.bkt.clouddn.com/longmao.jpg)

